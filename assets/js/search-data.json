{
  
    
        "post0": {
            "title": "Jigsaw Benchmark",
            "content": "In this post we will be looking at creating a benchmark model for Jigsaw Multilingual Toxic Comment Classification Kaggle competition. . We will be using the wonderful transformers library from Hugging Face and as mentioned in my previous post we will be using a translated version of the test dataset to create a benchmark model. . from transformers import BertForSequenceClassification, BertConfig, BertTokenizer from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule from tqdm.notebook import tqdm import torch.nn as nn import torch import pandas as pd . /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;. _np_qint8 = np.dtype([(&#34;qint8&#34;, np.int8, 1)]) /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;. _np_quint8 = np.dtype([(&#34;quint8&#34;, np.uint8, 1)]) /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;. _np_qint16 = np.dtype([(&#34;qint16&#34;, np.int16, 1)]) /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;. _np_quint16 = np.dtype([(&#34;quint16&#34;, np.uint16, 1)]) /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;. _np_qint32 = np.dtype([(&#34;qint32&#34;, np.int32, 1)]) /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;. np_resource = np.dtype([(&#34;resource&#34;, np.ubyte, 1)]) . import logging logger = logging.getLogger() logger.setLevel(logging.INFO) logging.info(&quot;test&quot;) . INFO:root:test . Tokenizer . We create a very basic Tokenizer class that creates a BertTokenizer from a pretrained multilingual model. The multilingual model that we will be using in this benchmark model is bert-base-multilingual-cased. We also write a __call__ method inside the Class which calls the encode_plus function on the BertTokenizer that returns a dictionary of input_ids, token_type_ids and attention_mask that are all fed to Bert model. . class Tokenizer: def __init__(self, model_name): self.tokenizer = BertTokenizer.from_pretrained(model_name) def __call__(self, input, **kwargs): return self.tokenizer.encode_plus(input, **kwargs) . tok = Tokenizer(&#39;bert-base-multilingual-cased&#39;) tok(&quot;Hello, how are you?&quot;, add_special_tokens=True) . INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729 . {&#39;input_ids&#39;: [101, 31178, 117, 14796, 10301, 13028, 136, 102], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1]} . Bert Model . Again, we create a BertModel class that is a thin wrapper around the BertForSequenceClassification class from Hugging Face and we update the final classifier layer to have only 1 final output because this a binary classification problem. We also update the __getattr__ method such that any lookup for an attribute that is not present in the BertModel class is passed on to self.model ie., to BertForSequenceClassification. This is done such that we still keep all the functionality that is already available. . class BertModel: def __init__(self, model_name, no=1): self.model = BertForSequenceClassification.from_pretrained(model_name) if self.model.classifier.out_features != no: self.model.classifier = nn.Linear(768, 1, bias=True) def __call__(self, *args, **kwargs): if &#39;target&#39; in kwargs.keys(): del kwargs[&#39;target&#39;] return self.model(*args, **kwargs) def __getattr__(self, attr): return getattr(self.model, attr) . model = BertModel(&#39;bert-base-multilingual-cased&#39;) . INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.893eae5c77904d1e9175faf98909639d3eb20cc7e13e2be395de9a0d8a0dad52 INFO:transformers.configuration_utils:Model config BertConfig { &#34;_num_labels&#34;: 2, &#34;architectures&#34;: [ &#34;BertForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;bad_words_ids&#34;: null, &#34;bos_token_id&#34;: null, &#34;decoder_start_token_id&#34;: null, &#34;directionality&#34;: &#34;bidi&#34;, &#34;do_sample&#34;: false, &#34;early_stopping&#34;: false, &#34;eos_token_id&#34;: null, &#34;finetuning_task&#34;: null, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;id2label&#34;: { &#34;0&#34;: &#34;LABEL_0&#34;, &#34;1&#34;: &#34;LABEL_1&#34; }, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;is_decoder&#34;: false, &#34;is_encoder_decoder&#34;: false, &#34;label2id&#34;: { &#34;LABEL_0&#34;: 0, &#34;LABEL_1&#34;: 1 }, &#34;layer_norm_eps&#34;: 1e-12, &#34;length_penalty&#34;: 1.0, &#34;max_length&#34;: 20, &#34;max_position_embeddings&#34;: 512, &#34;min_length&#34;: 0, &#34;model_type&#34;: &#34;bert&#34;, &#34;no_repeat_ngram_size&#34;: 0, &#34;num_attention_heads&#34;: 12, &#34;num_beams&#34;: 1, &#34;num_hidden_layers&#34;: 12, &#34;num_return_sequences&#34;: 1, &#34;output_attentions&#34;: false, &#34;output_hidden_states&#34;: false, &#34;output_past&#34;: true, &#34;pad_token_id&#34;: 0, &#34;pooler_fc_size&#34;: 768, &#34;pooler_num_attention_heads&#34;: 12, &#34;pooler_num_fc_layers&#34;: 3, &#34;pooler_size_per_head&#34;: 128, &#34;pooler_type&#34;: &#34;first_token_transform&#34;, &#34;prefix&#34;: null, &#34;pruned_heads&#34;: {}, &#34;repetition_penalty&#34;: 1.0, &#34;task_specific_params&#34;: null, &#34;temperature&#34;: 1.0, &#34;top_k&#34;: 50, &#34;top_p&#34;: 1.0, &#34;torchscript&#34;: false, &#34;type_vocab_size&#34;: 2, &#34;use_bfloat16&#34;: false, &#34;vocab_size&#34;: 119547 } INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059 INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;] . Let&#39;s do a quick test to make sure that our model works. Currently the outputs are not fine-tuned for a toxic classification task and we will have to train the network for the target task to have the correct outputs. But it is good to know that we can call the model and it seems to be spitting out some outputs. It is good to have these tiny tests to make sure that what we have done so far works. . input_ids = torch.tensor(tok(&quot;Hello, my dog is cute&quot;, add_special_tokens=True)[&#39;input_ids&#39;], dtype=torch.long).unsqueeze(0) # Batch size 1 labels = torch.tensor([1]).unsqueeze(0) # Batch size 1 outputs = model(input_ids) outputs . (tensor([[-0.1491]], grad_fn=&lt;AddmmBackward&gt;),) . Dataset . Finally we have to create a Dataset that will then be used to create DataLoader which will be used for training. We use the valid_translated file for training - the reason why we are not using the train.csv file is because the test set and the valid set were translated by using the Yandex API. If we use the train file, then the similarity of words between valid and train will be different (this is my assumption) and training directly on the validation file should work. At least, this is my understanding. . df = pd.read_csv(&quot;./jigsaw_miltilingual_valid_translated.csv&quot;, usecols=[&#39;translated&#39;, &#39;toxic&#39;]) df.head() . translated toxic . 0 This user does not even make it to the rank of... | 0 | . 1 The text of this entry appears to be like I di... | 0 | . 2 It is worth it. Only expose my past. All time ... | 1 | . 3 Of this article as a sub-heading with maintain... | 0 | . 4 I guess while they&#39;re At of the city, district... | 0 | . We create a simple BertDataset class that returns a dictionary containing the targets if the dataset is in training otherwise it doesn&#39;t return the targets. We add this custom behavior such that the same class can be used to create a train and test dataset. Rest of the methods are pretty simple - we initialize our tokenizer, in __getitem__ tokenize the ith row of dataframe and return it along with attention_mask, token_type_ids and maybe target. . One thing that we also do is to pad the sequences, we do this so that we can collate and run the model as a batch. If the sequence lengths are the same, then they can be concatenated and we can make the call to a model in a batch. . class BertDataset(): def __init__(self, csv_path, usecols, model_name=&#39;bert-base-multilingual-cased&#39;, max_len=512, textcol=&#39;translated&#39;, train=True): self.df = pd.read_csv(csv_path, usecols=None if usecols is None else usecols) self.tok = Tokenizer(model_name) self.max_len = max_len self.textcol = textcol self.train = train def __len__(self): return len(self.df) def __getitem__(self, idx): comment = self.df.iloc[idx][self.textcol] if self.train: target = self.df.iloc[idx].toxic # encode comment t_out = self.tok(comment, add_special_tokens=True, max_length=self.max_len) input_ids = t_out[&#39;input_ids&#39;] token_type_ids = t_out[&#39;token_type_ids&#39;] attention_mask = t_out[&#39;attention_mask&#39;] # pad sequences padding_length = self.max_len - len(input_ids) input_ids = input_ids + ([0] * padding_length) attention_mask = attention_mask + ([0] * padding_length) token_type_ids = token_type_ids + ([0] * padding_length) return { &#39;input_ids&#39;: torch.tensor(input_ids, dtype=torch.long), &#39;attention_mask&#39;: torch.tensor(attention_mask, dtype=torch.long), &#39;token_type_ids&#39;: torch.tensor(token_type_ids, dtype=torch.long), &#39;target&#39;: torch.tensor(target, dtype=torch.float) } if self.train else { &#39;input_ids&#39;: torch.tensor(input_ids, dtype=torch.long), &#39;attention_mask&#39;: torch.tensor(attention_mask, dtype=torch.long), &#39;token_type_ids&#39;: torch.tensor(token_type_ids, dtype=torch.long), } . dataset = BertDataset(csv_path=&quot;./jigsaw_miltilingual_valid_translated.csv&quot;, usecols=[&#39;translated&#39;, &#39;toxic&#39;]) . INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729 . Dataloader . Finally we create a dataloader. This works because we padded the sequences inside our dataset. If we had not paded the sequences the dataloader would not have been able to collate the sequences due to different sequence lengths and thrown an error. . dataloader = torch.utils.data.DataLoader(dataset, batch_size=4) . Let&#39;s do a quick test to make sure that the dataloader works. . # make sure dataloader works next(iter(dataloader)) . {&#39;input_ids&#39;: tensor([[ 101, 10747, 29115, ..., 0, 0, 0], [ 101, 10117, 15541, ..., 0, 0, 0], [ 101, 10377, 10124, ..., 0, 0, 0], [ 101, 12610, 10531, ..., 0, 0, 0]]), &#39;attention_mask&#39;: tensor([[1, 1, 1, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0]]), &#39;token_type_ids&#39;: tensor([[0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]]), &#39;target&#39;: tensor([0., 0., 1., 0.])} . model(**next(iter(dataloader))) . (tensor([[-0.0938], [-0.1023], [-0.0882], [-0.1240]], grad_fn=&lt;AddmmBackward&gt;),) . Train . Finally, we create a loss_fn that will be used to generate loss between outputs and inputs. . def loss_fn(outputs, targets): return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1)) . We also create a list of optimizer with and without weight_decay that we will be passed to the Optimizer - so we create two param groups. . param_optimizer = list(model.named_parameters()) no_decay = [&#39;bias&#39;, &#39;LayerNorm.bias&#39;, &#39;LayerNorm.weight&#39;] optimizer_grouped_parameters = [ {&#39;params&#39;: [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], &#39;weight_decay&#39;: 0.001}, {&#39;params&#39;: [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], &#39;weight_decay&#39;: 0.0}] . num_train_steps = int(len(dataset) / 64 * 5) . Finally we initialize our Optimizer and Scheduler and initialize device as cuda. . optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5) scheduler = get_linear_schedule_with_warmup( optimizer, num_warmup_steps=0, num_training_steps=num_train_steps ) device = &#39;cuda&#39; . model = model.to(&#39;cuda&#39;) . Below is a very basic training loop since this is a benchmark model. . model.train() for epoch in tqdm(range(5)): for bi, d in tqdm(enumerate(dataloader), total=len(dataloader)): input_ids = d[&quot;input_ids&quot;] attention_mask = d[&quot;attention_mask&quot;] token_type_ids = d[&quot;token_type_ids&quot;] targets = d[&quot;target&quot;] input_ids = input_ids.to(device, dtype=torch.long) attention_mask = attention_mask.to(device, dtype=torch.long) token_type_ids = token_type_ids.to(device, dtype=torch.long) targets = targets.to(device, dtype=torch.float) optimizer.zero_grad() outputs = model( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids )[0] loss = loss_fn(outputs, targets) loss.backward() optimizer.step() if scheduler is not None: scheduler.step() . . Predictions . Now once the model is trained we are ready to make predictions, we create a test dataset with the jigsaw_miltilingual_test_translated.csv file and make predictions on this file. . test_dataset = BertDataset(csv_path=&quot;./jigsaw_miltilingual_test_translated.csv&quot;, usecols=[&#39;translated&#39;], textcol=&#39;translated&#39;, train=False) . INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729 . test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8) . Below is a very basic prediction test loop that is a copy of the training loop without the loss.backward() and with a torch.no_grad to save GPU memory because during testing we are not worried about the gradients. . model.eval() preds = [] with torch.no_grad(): for bi, d in tqdm(enumerate(test_dataloader), total=len(test_dataloader)): input_ids = d[&quot;input_ids&quot;] attention_mask = d[&quot;attention_mask&quot;] token_type_ids = d[&quot;token_type_ids&quot;] input_ids = input_ids.to(device, dtype=torch.long) attention_mask = attention_mask.to(device, dtype=torch.long) token_type_ids = token_type_ids.to(device, dtype=torch.long) optimizer.zero_grad() outputs = model( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids )[0] outputs_np = outputs.cpu().detach().numpy().tolist() preds.extend(outputs_np) . . We take a sigmoid to convert the predictions to range (0,1). . _preds = torch.sigmoid(torch.tensor(preds)) _preds.shape . torch.Size([63812, 1]) . _preds.squeeze() . tensor([0.0161, 0.0169, 0.4494, ..., 0.2997, 0.0194, 0.0184]) . submission = pd.read_csv(&quot;./sample_submission.csv&quot;) submission[&#39;toxic&#39;] = _preds.squeeze() submission.to_csv(&quot;submission.csv&quot;, index=False) . Now we can simply update this model to Kaggle Kernel and make predictions on the competition. . torch.save(model.state_dict(), &#39;./first.bin&#39;) . I have created a basic benchmark kernel here and we get a score of 0.8808 on this benchmark model which is trained on very little data in much less time. This is pretty encouraging. . More to come in the next blogposts! .",
            "url": "https://amaarora.github.io/jigsaw/2020/04/11/Jigsaw-Benchmark.html",
            "relUrl": "/2020/04/11/Jigsaw-Benchmark.html",
            "date": " • Apr 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Jigsaw Benchmark Experiment",
            "content": "I wanted to try a tiny little experiment of submitting the multilingual model without any training to check the basic score that we get. . I followed the same script to make a submission and got a score of 0.5630. So, this makes me happy that the model we used in the previous post is definitely learning how to classify toxicity. . Now we will move forward to try out training our multilingual model for various different languages in the test set to classify toxicity. . Stay tuned for more! .",
            "url": "https://amaarora.github.io/jigsaw/2020/04/11/Jigsaw-Benchmark-Experiment.html",
            "relUrl": "/2020/04/11/Jigsaw-Benchmark-Experiment.html",
            "date": " • Apr 11, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Jigsaw Multilingual Toxic Comment Classification",
            "content": "# from transformers import XLMRobertaConfig, XLMRobertaTokenizer, XLMRobertaModel import pandas as pd %matplotlib inline . This is a really interesting competition - and in this competition I want to learn as well as teach - learn by experimenting new techniques and teach by showing the how to do the experiments. I hope you find this blogpost interesting because each week, I will perform a new experiment and get an intuition on what works and what doesn&#39;t work. . What&#39;s so interesting about this competition? . Well, firstly, the training data is only in En while the valid and test set contain multiple languages. . trn = pd.read_csv(&quot;./jigsaw-toxic-comment-train.csv&quot;, usecols=[&#39;comment_text&#39;, &#39;toxic&#39;]) trn.head() . comment_text toxic . 0 Explanation nWhy the edits made under my usern... | 0 | . 1 D&#39;aww! He matches this background colour I&#39;m s... | 0 | . 2 Hey man, I&#39;m really not trying to edit war. It... | 0 | . 3 &quot; nMore nI can&#39;t make any real suggestions on ... | 0 | . 4 You, sir, are my hero. Any chance you remember... | 0 | . Here is a list of 5 toxic comments in the train set: . list(trn.query(&quot;toxic==1&quot;).comment_text[:5]) . [&#39;COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK&#39;, &#39;Hey... what is it.. n@ | talk . nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP? n nAsk Sityush to clean up his behavior than issue me nonsensical warnings...&#39;, &#34;Bye! n nDon&#39;t look, come or think of comming back! Tosser.&#34;, &#34;You are gay or antisemmitian? n nArchangel WHite Tiger n nMeow! Greetingshhh! n nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone... n n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings! n n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals! n n3 - First and last warning, you fucking gay - I won&#39;t appreciate if any more nazi shwain would write in my page! I don&#39;t wish to talk to you anymore! n nBeware of the Dark Side!&#34;, &#39;FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!&#39;] . So, the training set only consists of comment_text field in English and toxic field that represents whether the comment is toxic or not. . valid = pd.read_csv(&#39;./validation.csv&#39;) valid.head() . id comment_text lang toxic . 0 0 | Este usuario ni siquiera llega al rango de ... | es | 0 | . 1 1 | Il testo di questa voce pare esser scopiazzato... | it | 0 | . 2 2 | Vale. Sólo expongo mi pasado. Todo tiempo pasa... | es | 1 | . 3 3 | Bu maddenin alt başlığı olarak uluslararası i... | tr | 0 | . 4 4 | Belçika nın şehirlerinin yanında ilçe ve belde... | tr | 0 | . set(valid.lang) . {&#39;es&#39;, &#39;it&#39;, &#39;tr&#39;} . The valid set consists of &#39;es&#39; (ISO code for Spanish), &#39;it&#39; (ISO code for Italian) and &#39;tr&#39; (ISO code for Turkish). You can find the ISO codes for reference here. . Now what about the test set? . test = pd.read_csv(&#39;./test.csv&#39;) test.head() . id content lang . 0 0 | Doctor Who adlı viki başlığına 12. doctor olar... | tr | . 1 1 | Вполне возможно, но я пока не вижу необходимо... | ru | . 2 2 | Quindi tu sei uno di quelli conservativi , ... | it | . 3 3 | Malesef gerçekleştirilmedi ancak şöyle bir şey... | tr | . 4 4 | :Resim:Seldabagcan.jpg resminde kaynak sorunu ... | tr | . set(test.lang) . {&#39;es&#39;, &#39;fr&#39;, &#39;it&#39;, &#39;pt&#39;, &#39;ru&#39;, &#39;tr&#39;} . The valid set consists of &#39;es&#39; (ISO code for Spanish), &#39;fr&#39; (ISO code for French), &#39;it&#39; (ISO code for Italian), &#39;pt&#39; (ISO code for Portuguese, &#39;ru&#39; (ISO code for Russian) and &#39;tr&#39; (ISO code for Turkish). You can find the ISO codes for reference here. . Interesting right? So can we train a toxic comment classifier on English and use it on another language? I say &quot;No&quot;. . Why? . Tokens are different: The first step of a language model is to create a tokenizer and convert the input text to tokens, how will our model treat two different languages or multiple different languages if it doesn&#39;t know how to tokenize them? | No common embedding represenation: The tokens are converted to some intermediate representations of some dimension - in case of BERT it&#39;s 768, and then the model performs the classification on these intermediate representations. How will our model know which representation to use if it&#39;s only trained on English? | . So what do we do then? . Well, we make use of multilingual transformer based models. Recently there has been much research in multilingual models - one model for multiliple languages. . From what I&#39;ve read through the Kaggle forums and recent research papers, there are two main multilingual models - one of them by Facebook AI - XLM, XLMR and another one by Google - MBert (multilingual bert). . There is a great introduction to this competition using mBert available here. . While at the same time there is also much interesting discussion about using XLM-R here. . Now which of the two is better - I do not know. BUT, we will found out through expirementation. At the date of writing this blogpost, there are still two more months to go and while at this time I cannot aim to win the competition - I do aim to get a gold medal or at the least implement these new ideas to learn. . Could we use translation? . Another idea is to then translate the test set to English and use a mono lingual English model for toxicity classification. A translated version of the test set is available here. . val_translated = pd.read_csv(&quot;./jigsaw_miltilingual_valid_translated.csv&quot;) val_translated.head() . id comment_text translated lang toxic . 0 0 | Este usuario ni siquiera llega al rango de ... | This user does not even make it to the rank of... | es | 0 | . 1 1 | Il testo di questa voce pare esser scopiazzato... | The text of this entry appears to be like I di... | it | 0 | . 2 2 | Vale. Sólo expongo mi pasado. Todo tiempo pasa... | It is worth it. Only expose my past. All time ... | es | 1 | . 3 3 | Bu maddenin alt başlığı olarak uluslararası i... | Of this article as a sub-heading with maintain... | tr | 0 | . 4 4 | Belçika nın şehirlerinin yanında ilçe ve belde... | I guess while they&#39;re At of the city, district... | tr | 0 | . list(val_translated.query(&quot;toxic==1&quot;).translated[5:10]) . [&#34;BREED OF IDIOTS!!! You&#39;re drunk, your brain???? What is this intrusion????? Your troubles personal risolvetele on your pages (personal)! In addition, I have voted for the cancellation!!! Then go to .....the! &#34;, &#39;The title should linklenme of pornography. Though critical of the substance that should have a hanging this pervert get more scientific writing.95.7.150.Forty five &#39;, &#34;makes you so disgusting, leave double space?Mpiz (msg) ah, inveve is really nice to have all the paragraphs stuck that you don&#39;t know even where start one and ends the other..it is just belloMpiz (msg) is, but the lines so they are all stuck and do not understand a football club. with the double space remaining slightly more spaced out, even at a glance see where finishes one and starts the next.Mpiz (msg) &#34;, &#34;Hello really thought about it, that you are not going to find it?, I told you, I&#39;m tracking, I&#39;m tracking your comments, your insults, your whining, you&#39;ll soon know me.&#34;, &#39;Eh excuse me, but She is a communist and illiberal, with all these cancellations! SERGIUS (CATUS NIGER) &#39;] . Above, I have shared 10 translated comments that are toxic. The translated versions of comments do seem to be toxic if you read it in plain English and it is possible that this approach of toxicity classification might work. But, then out training set needs to have the same words for toxic classification too. One approach is to finetune the model on the valid set and use the same API (for translation) on the test set and then make predictions on the test set. . This approach assumes that the translation API used (in this case YANDEX) will not remove the toxicity and that it can mantain a good level of translation accuracy for multiple languages - especially those in the test set. . A downside of this would we that if such a model is served in production - each sentence would have to be translated first before we are able to classify the toxicity on the comment. . test_translated = pd.read_csv(&quot;./jigsaw_miltilingual_test_translated.csv&quot;) test_translated.head() . id content lang translated . 0 0 | Doctor Who adlı viki başlığına 12. doctor olar... | tr | Title named Doctor Who wiki 12. doctor has add... | . 1 1 | Вполне возможно, но я пока не вижу необходимо... | ru | It is possible, but I don&#39;t see the need to a... | . 2 2 | Quindi tu sei uno di quelli conservativi , ... | it | Then you&#39;re one of those conservative , who wo... | . 3 3 | Malesef gerçekleştirilmedi ancak şöyle bir şey... | tr | Unfortunately, it was not performed, but had s... | . 4 4 | :Resim:Seldabagcan.jpg resminde kaynak sorunu ... | tr | :Resim:Seldabagcan.jpg the image of the source... | . list(test_translated.translated[95:100]) . [&#39;Hello, Qbert88. I am writing to you because you are in the list of users of Emilia-Romagna, and I wanted to tell you about the next wikiraduno in Bologna from the 11th to the 15th of June 2008. If you have the desire or time to come you will find all the information on the page of the gathering. Xaura (msg) &#39;, &#34;Z have understood nothing... It&#39;s supposed to be ironic, and rightly so. Steve Rogers represents all that the Nazis (racist and eugenic) dreaming on the physical plane, but on the moral plane hates everything they represent, and becomes their worst enemy.216.15.41.45 (d) &#34;, &#34;I bet your mother is still working !!! d the other hand, the whores work late !!! I&#39;m sure you&#39;re a loser nerd shit behind a computer who likes to make the dick and then go fuck and blocks I&#39;m fucking ugly nerd fucking D&#34;, &#39;Hello Huster, I am a new contributor and I note your change of categorization of the article on the Red Cross of Belgium. What principle has motivated this amendment? Sincerely, C is very clear indeed. I was not happy with this large hierarchy of categories. Thank you, &#39;, &#39;right|70pxCiao , the page &#34;Template:MinistroEconomiaItaliano&#34; that you wrote, or that you collaborated to write, has been proposed for deletion. If you don &#39;t want the page deleted, read the rules on the cancellation and join in the discussion . (If the page had already been deleted by mistake , you can contact administrators asking that it be restored.) Kal - El &#39;] . The test set seems to have translated and retained the toxicity too. It is possible that some of the toxic comments were not translated properly while others were. . Any other ideas? . Surely translating the test set and making predictions on that will serve as a good benchmark, in fact we will be using this approach to create a benchmark model. . Personally though I believe that translating every language correctly with high BLEU and mantain toxicity is a harder task then classifying toxicity on these languages. . For this competition we could have multiple monolingual models for each language that are then used for classification of toxicity. | We could find multiple datasets outside of the one provided and train/fine-tune a multilingual model to classify for toxicity. | We could translate the train set to multiple languages and then use that to train a multilingual model. | Personally, currently I believe that using approach 1 or approach 2 will work the best. In the next blog, we will create a benchmark using the translated test set. And then we will move on to approach 1 and 2. See you in the next blog! .",
            "url": "https://amaarora.github.io/jigsaw/2020/04/10/JigsawIntro.html",
            "relUrl": "/2020/04/10/JigsawIntro.html",
            "date": " • Apr 10, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am a Data Scientist at CoreLogic Australia where I spend a lot of my time building SOTA algorithms to predict house and rental prices across all of Australia and NZ. At CoreLogic, I have been responsible for building the Rental AVM product from scratch for over 10 million properties which led to an overall 8% increase in predictions nationally. . I have a passion for deep learning, thanks to Jeremy Howard who made it possible for me through fast.ai to begin my journey in this space around 1.5 years ago. . I am self taught, and an ardent follower of and small contributor to the fast.ai course. Through this course itself, I have been able to pickup Python and it has made possible for me to do my own research. Something, I would have not thought of being able to do when I first started. I believe I still have a lot to learn and commit myself to learning something new every day. . I also fimly believe in giving back to the community and in that attempt, also run a meetup group called Applied Data Science. The focus in this blog is on writing code as much as it is on explaining the concept in theory. . If you feel that any of these ideas can be expressed in a better way, I am very happy to receive constructive feedback. Please feel free to reach out to me via twitter. .",
          "url": "https://amaarora.github.io/jigsaw/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://amaarora.github.io/jigsaw/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}